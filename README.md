# ğŸ“– Confession AI

> **A private AI-powered Confession Reflection app** â€” helps users reflect spiritually by preparing or practicing confessions in a safe, calming environment.  
>  
> ğŸŒŸ Powered by React.js + FastAPI + Local AI Model (Ollama).

---

## ğŸ“¸ Preview
![image](https://github.com/user-attachments/assets/20320044-cb62-4f79-ad5a-43d1e6591e65)


---

## âœ¨ Features
- ğŸ“ Write your personal confessions.
- ğŸ¤– Receive gentle, compassionate reflections from a local AI model.
- ğŸ›¡ï¸ 100% private â€” no user data is stored.
- ğŸŒ™ Calm and minimalist design with TailwindCSS.
- ğŸš€ Fast, full-stack setup using Vite + FastAPI.

---

## ğŸ› ï¸ Tech Stack

| Frontend | Backend | AI |
|:---------|:--------|:---|
| React.js (Vite) | FastAPI (Python) | Local Ollama Model (e.g., Llama3, Mistral) |
| TailwindCSS | Uvicorn server | |

---

## ğŸš€ How to Run Locally

### 1. Clone the Repo

```bash
git clone https://github.com/your-username/confession-ai.git
cd confession-ai
```

---

### 2. Set Up Backend (FastAPI)

```bash
cd backend
pip install -r requirements.txt
```

Start the backend server:

```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

âœ… API will run at `http://localhost:8000`.

---

### 3. Set Up Local AI Model (Ollama)

Install [Ollama](https://ollama.com/) and run your model (example: llama3):

```bash
ollama run llama3
```

âœ… Ollama server will run at `http://localhost:11434`.

---

### 4. Set Up Frontend (React.js)

```bash
cd ../frontend
npm install
npm run dev
```

âœ… Frontend will run at `http://localhost:5173`.

---

## âš¡ Quick Summary

| Part | URL |
|:-----|:----|
| Frontend (React.js) | `http://localhost:5173` |
| Backend (FastAPI) | `http://localhost:8000/confess` |
| Local AI Model (Ollama) | `http://localhost:11434` |

---

## ğŸ“‚ Project Structure

```
confession-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ ai_model.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ index.css
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ postcss.config.js
â”œâ”€â”€ README.md
```

---

## ğŸ§  Future Improvements
- Loading animation during AI thinking
- Session-based confession history
- Guided "Examination of Conscience" mode
- Deployment to Vercel (Frontend) and Render.com (Backend)
- Optional calming background music

---

## ğŸ“„ License
This project is licensed under the MIT License.  
Feel free to use and adapt it with proper credit. ğŸŒŸ

---

# ğŸ™ Final Note
> This website is meant for spiritual reflection preparation only and does **not replace the Sacrament of Reconciliation**.  
> Please seek a priest for official confession and absolution. âœï¸

---

# ğŸ“£ Acknowledgements
- [Ollama](https://ollama.com/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Vite](https://vitejs.dev/)
- [TailwindCSS](https://tailwindcss.com/)

---
